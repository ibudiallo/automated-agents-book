When we bought our very first PlayStation console, it came with *Tekken 3*. We played almost every single day. My favorite character was Eddie Gordo, and unlike the newbies who just mashed random buttons, I actually knew how to play him. But one thing that always fascinated me in *Tekken* was the behavior of the CPU-controlled opponents. In practice mode, you could configure your opponent to block every single attack. No matter what move I tried, the CPU would effortlessly anticipate and block it, almost as if it were reading my mind. Switch the mode to attacking, and suddenly the CPU would give me a beating like a pro player.

When I was a kid, we called it the CPU. Today, most people would call it the "AI" in the game. However, looking back, I realize that the humble PS One didn’t have the resources to run anything close to what we now call artificial intelligence. It wasn’t "thinking" or predicting my moves like modern AI might; it was just a well-written program executing specific rules set by the developers. In fact, even in many modern games, CPU opponents still don’t use true AI. They rely on complex patterns and scripted responses to simulate intelligence.

This brings us to an interesting observation: the term "AI" is often used as a catch-all for any complex, intelligent-seeming software. But in reality, much of what we call AI today—especially in video games or even some chatbots—isn’t intelligence in the human sense. It's simply advanced programming designed to give the illusion of intelligence.

As the saying goes, "Any sufficiently advanced software is indistinguishable from AI." Whether it’s a character blocking every move in *Tekken* or a chatbot answering questions, the line between advanced software and what we perceive as AI often gets blurred. In this chapter, we'll explore what AI really is, how it's different from other forms of software, and how it fits into the bigger picture—especially when building chatbots.

### What is AI?

Artificial Intelligence refers to the simulation of human intelligence by machines that are designed to perform tasks that typically require human cognitive functions, such as problem-solving, learning, and understanding language. AI has many applications, but when it comes to chatbots, we're working with a specific subset of AI.

In the context of chatbots, AI is not a monolithic entity. It relies on several key components working together:

- **Classifier:** This helps the chatbot understand the intent behind a user's message. For example, when a customer asks, "Where is my order?" the classifier identifies that the intent is to request order tracking information.

- **Sentiment Analyzer:** This AI tool gauges the emotional tone of a customer’s message. It can detect whether a customer is frustrated, satisfied, or neutral. A sentiment analyzer helps the chatbot adjust its responses, offering more empathetic replies when dealing with an upset customer.

- **Entity Recognition:** This component identifies specific pieces of information from a user's message, such as dates, locations, product names, or order numbers. If a customer asks, "Where is my blue jacket?" the entity recognizer will extract "blue jacket" as the relevant item.

Each of these AI tools works in tandem to make chatbots more responsive and capable of handling complex customer inquiries. Instead of a simple script that looks for keywords, AI in chatbots ensures better understanding and more personalized interactions, improving the overall customer experience.

When we think of AI in the context of chatbots, it’s easy to imagine a single, all-encompassing model that handles everything from understanding the user’s intent to generating a response. But in reality, we can leverage multiple AI models, each with their own unique specialty.

By using multiple AI passes, we can extract more nuanced information from user messages, making the chatbot not only more responsive but also more empathetic and contextually aware. This multi-layered approach ensures that the chatbot isn’t just reacting to what the customer is saying but is also considering how they are saying it and why they might be saying it. Each additional AI model we add becomes a new feature that can enhance the chatbot’s effectiveness in resolving customer issues.

## The Hand off

In an ideal world, a chatbot or AI system would be able to handle every customer inquiry seamlessly. However, the reality is that AI has limitations and can't always provide the necessary solution. When a chatbot encounters an issue it cannot resolve, the next step is crucial: the hand-off to a human agent.

The hand-off process is not just about transferring the conversation; it's about ensuring a smooth transition from automated to human assistance. When an AI can't answer a question or resolve an issue, it should be able to recognize its limitations and immediately initiate a hand-off. This is vital to maintaining a positive customer experience, as a quick and efficient hand-off shows that the company values their time and concerns.

During this transition, the AI should collect as much relevant information as possible about the customer's query. This might include the nature of the issue, any attempted solutions, the customer's mood or sentiment, and any contextual data such as order history or previous interactions. By packaging this information and presenting it to the human agent, the AI can help streamline the support process. This way, the agent has all the context they need to effectively resolve the issue without making the customer repeat themselves. 

A well-executed hand-off not only saves time but also enhances the customer experience by ensuring that the human agent is fully informed and ready to assist. The goal is to make the transition feel seamless, minimizing any frustration the customer might feel and maximizing their satisfaction with the service they receive. In the end, while AI can handle many tasks, the ability to recognize when it needs to step back and pass the baton to a human is just as critical to the success of a chatbot.


## Keeping the AI Models up to date

AI models are only as good as the data they are trained on, and in the diverse world of eCommerce, customer communication varies significantly across different platforms and product types. For example, customers buying digital goods often use jargon that is unique to the tech-savvy community, while those purchasing physical arts and craft may use language that is more descriptive and emotive.

This variation in language can become a challenge for AI models, especially when they are trained primarily on data from one type of customer. An AI model optimized for handling inquiries about software downloads might struggle to accurately classify and respond to questions about handcrafted jewelry.

This is why it is important to have a robust training pipeline in place to allow regular updates of the AI models. This pipeline should focus on three areas in order of priority:

1. Handling False Positives:  
   False positives occur when the AI misclassifies a customer inquiry, leading to an incorrect or irrelevant response. By having a path in place to identify and report these errors, the model can be improved immediately.  
2. Addressing Low Confidence Scores:  
   When the AI encounters a message it is unsure about, it gives it a low score. These low score interactions are a goldmine for improving the model.  
3. Random Sample of new messages:  
   When starting integration with a new company, it is important to grab a random sample of the messages they receive and train the models with it. This ensures that false positives are less likely to occur.

Regularly updating the AI models through this pipeline not only improves their ability to classify and respond to a wider range of customer inquiries but also ensures that the chatbot remains relevant as customer communication styles evolve. Continuous training allows the chatbot to adapt to new trends, slang, and industry-specific language, ultimately expanding the number of customers it can assist effectively.

Training the model means having humans look at customer messages and decide what they actually mean. This means exposing customer personal information. To properly perform training, we need to take security and data privacy into account.

![Training](./asset/images/training.svg)