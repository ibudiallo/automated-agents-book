When we bought our very first PlayStation console, it came with *Tekken 3*. We played almost every single day. My favorite character was Eddie Gordo, and unlike the newbies who just mashed random buttons, I actually knew how to play him. But one thing that always fascinated me in *Tekken* was the behavior of the CPU-controlled opponents. In practice mode, you could configure your opponent to block every single attack. No matter what move I tried, the CPU would effortlessly anticipate and block it, almost as if it were reading my mind. Switch the mode to attacking, and suddenly the CPU would give me a beating like a pro player.

When I was a kid, we called it the CPU. Today, most people would call it the "AI" in the game. However, looking back, I realize that the humble PS One didn’t have the resources to run anything close to what we now call artificial intelligence. It wasn’t "thinking" or predicting my moves like modern AI might; it was just a well-written program executing specific rules set by the developers. In fact, even in many modern games, CPU opponents still don’t use true AI. They rely on complex patterns and scripted responses to simulate intelligence.

This brings us to an interesting observation: the term "AI" is often used as a catch-all for any complex, intelligent-seeming software. But in reality, much of what we call AI today—especially in video games or even some chatbots—isn’t intelligence in the human sense. It's simply advanced programming designed to give the illusion of intelligence.

As the saying goes, "Any sufficiently advanced software is indistinguishable from AI." Whether it’s a character blocking every move in *Tekken* or a chatbot answering questions, the line between advanced software and what we perceive as AI often gets blurred. In this chapter, we'll explore what AI really is, how it's different from other forms of software, and how it fits into the bigger picture—especially when building chatbots.

## Do we need more AI?

The process I described can resolve the majority of issues, but there is always room for improvement. When we think of AI in the context of chatbots, it’s easy to imagine a single, all-encompassing model that handles everything from understanding the user’s intent to generating a response. But in reality, we can leverage multiple AI models, each with their own unique specialty. This approach can improve the user’s experience and can also give us a way to introduce new features.

For example, consider the original user input. Instead of sending it through a single AI model, we can have it go through multiple passes.

1. **Classifier:** The first pass involves a classifier to determine the type of action the user wants. It could be asking about an order, returning a product, or needing technical support.  
2. **Sentiment Analysis:** The next pass could perform sentiment analysis to gauge the tone of the message. Understanding whether the customer is happy, frustrated, or neutral can influence how the chatbot responds. An angry customer likely doesn’t want any peppy talk. They just want their problem to be solved and be done with it.  
3. **Reason Classification:** Another pass could classify the reason behind the customer’s original message. For example, if a customer wants to return an order, they may include a reason. Such as the product not meeting their expectations. Extracting this information upfront can be valuable for tailoring the response.

By using multiple AI passes, we can extract more nuanced information from user messages, making the chatbot not only more responsive but also more empathetic and contextually aware. This multi-layered approach ensures that the chatbot isn’t just reacting to what the customer is saying but is also considering how they are saying it and why they might be saying it. Each additional AI model we add becomes a new feature that can enhance the chatbot’s effectiveness in resolving customer issues.

## The Hand off

In an ideal world, a chatbot or AI system would be able to handle every customer inquiry seamlessly. However, the reality is that AI has limitations and can't always provide the necessary solution. When a chatbot encounters an issue it cannot resolve, the next step is crucial: the hand-off to a human agent.

The hand-off process is not just about transferring the conversation; it's about ensuring a smooth transition from automated to human assistance. When an AI can't answer a question or resolve an issue, it should be able to recognize its limitations and immediately initiate a hand-off. This is vital to maintaining a positive customer experience, as a quick and efficient hand-off shows that the company values their time and concerns.

During this transition, the AI should collect as much relevant information as possible about the customer's query. This might include the nature of the issue, any attempted solutions, the customer's mood or sentiment, and any contextual data such as order history or previous interactions. By packaging this information and presenting it to the human agent, the AI can help streamline the support process. This way, the agent has all the context they need to effectively resolve the issue without making the customer repeat themselves. 

A well-executed hand-off not only saves time but also enhances the customer experience by ensuring that the human agent is fully informed and ready to assist. The goal is to make the transition feel seamless, minimizing any frustration the customer might feel and maximizing their satisfaction with the service they receive. In the end, while AI can handle many tasks, the ability to recognize when it needs to step back and pass the baton to a human is just as critical to the success of a chatbot.

## What is company policy?

Every eCommerce business operates under a set of policies that define how they interact with customers and fulfill their commitments. These policies are not just guidelines; they are promises made to customers, and they play a crucial role in how the company responds to customer inquiries.

For example, a company might have the following commitments:

* **Shipping Policy:** All purchased items will be shipped within 2 business days.  
* **Service Level Agreement (SLA):** Orders should arrive within 3 to 5 business days.  
* **Return Policy:** Items can be returned, no questions asked, within 30 days of purchase.  
* **Refund/Replacement Policy:** Damaged items reported within the first 10 days can be refunded or replaced. After 10 days, only replacements are offered.

These policies are not part of the AI model’s training. Instead, they are implemented at the application level, as a manual process that ensures alignment with the specific policies of the company. This distinction is crucial because it underscores that the chatbot’s role is to apply these predefined rules consistently, rather than relying on the AI to make decisions based on generalized training data.

For instance, if a customer asks for tracking information 10 minutes after placing an order, the AI isn’t making an arbitrary decision. Instead, the application applies the company’s shipping policy: "Your order is currently being processed and should ship within 2 business days. Once it ships, you’ll receive an email with the tracking information."

By embedding company policies into the application’s logic, you ensure that customer interactions are consistent and aligned with your business's commitments. This process requires manual configuration to match the company’s specific rules and policies, ensuring that the chatbot’s responses are accurate and reliable.

These policies can be structured into a decision tree that guides the chatbot’s responses for different scenarios:

* **Order Status Inquiries:** If a customer asks about their order before it’s shipped, the chatbot refers to the processing time. If it’s within the SLA window, the chatbot provides reassurance that the order is on track. If it’s beyond the SLA, the chatbot can escalate the issue or provide a more detailed explanation.  
* **Return Requests:** When a customer requests a return within the allowed 30-day window, the chatbot can immediately initiate the return process. If the request comes after 30 days, the chatbot might offer alternative solutions, such as store credit or an exchange, based on the company’s policy.  
* **Refund or Replacement for Damaged Items:** The chatbot can automatically check the date of the order and, if within the first 10 days, offer a refund or replacement. If it’s after 10 days, the chatbot follows the policy by offering only a replacement.

Integrating these policies into the chatbot at the application level, rather than through AI model training, not only ensures compliance but also enhances the customer experience by providing clear, consistent, and policy-driven responses. This reduces ambiguity, prevents potential disputes, and aligns the chatbot’s behavior with the company’s values and commitments.

## Keeping the AI Models up to date

AI models are only as good as the data they are trained on, and in the diverse world of eCommerce, customer communication varies significantly across different platforms and product types. For example, customers buying digital goods often use jargon that is unique to the tech-savvy community, while those purchasing physical arts and craft may use language that is more descriptive and emotive.

This variation in language can become a challenge for AI models, especially when they are trained primarily on data from one type of customer. An AI model optimized for handling inquiries about software downloads might struggle to accurately classify and respond to questions about handcrafted jewelry.

This is why it is important to have a robust training pipeline in place to allow regular updates of the AI models. This pipeline should focus on three areas in order of priority:

1. Handling False Positives:  
   False positives occur when the AI misclassifies a customer inquiry, leading to an incorrect or irrelevant response. By having a path in place to identify and report these errors, the model can be improved immediately.  
2. Addressing Low Confidence Scores:  
   When the AI encounters a message it is unsure about, it gives it a low score. These low score interactions are a goldmine for improving the model.  
3. Random Sample of new messages:  
   When starting integration with a new company, it is important to grab a random sample of the messages they receive and train the models with it. This ensures that false positives are less likely to occur.

Regularly updating the AI models through this pipeline not only improves their ability to classify and respond to a wider range of customer inquiries but also ensures that the chatbot remains relevant as customer communication styles evolve. Continuous training allows the chatbot to adapt to new trends, slang, and industry-specific language, ultimately expanding the number of customers it can assist effectively.

Training the model means having humans look at customer messages and decide what they actually mean. This means exposing customer personal information. To properly perform training, we need to take security and data privacy into account.

![Training](./asset/images/training.svg)